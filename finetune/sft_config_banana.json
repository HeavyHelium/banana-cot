{
  "model_name": "Qwen/Qwen2.5-0.5B-Instruct",
  "output_dir": "outputs/sft_banana",
  "train_data_path": "data/train_mul_banana.jsonl",
  "val_data_path": null,
  "max_seq_length": 1024,
  "num_epochs": 3,
  "per_device_train_batch_size": 2,
  "per_device_eval_batch_size": 2,
  "gradient_accumulation_steps": 8,
  "learning_rate": 2e-5,
  "weight_decay": 0.01,
  "warmup_ratio": 0.1,
  "lr_scheduler_type": "cosine",
  "fp16": false,
  "bf16": true,
  "gradient_checkpointing": true,
  "logging_steps": 10,
  "save_steps": 500,
  "save_total_limit": 3,
  "report_to": "wandb",
  "wandb_project": "banana-cot",
  "wandb_run_name": "sft-banana-attention-mask",
  "use_lora": false,
  "assistant_only_loss": true,
  "mask_final_answer_attention_to_prompt": true,
  "math_eval_jsonl_path": "evals/mul_eval_very_small.jsonl",
  "math_eval_max_new_tokens": 256,
  "math_eval_run_every_epoch": true,
  "seed": 42,
  "dataloader_num_workers": 4,
  "remove_unused_columns": false
}